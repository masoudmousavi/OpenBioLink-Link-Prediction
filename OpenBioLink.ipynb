{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenBioLink.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FjoSWK_TT4b",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f4daf8-9d5b-4492-eb01-ee6ad5ada356"
      },
      "source": [
        "#@title OpenBioLink Module Install EXTERNAL{ form-width: \"15%\" }\n",
        "! pip install openbiolink"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openbiolink in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from openbiolink) (7.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.9.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from openbiolink) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openbiolink) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->openbiolink) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->openbiolink) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.4->openbiolink) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->openbiolink) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyVfad59VpsU",
        "cellView": "form"
      },
      "source": [
        "#@title PyG Installation EXTERNAL{ form-width: \"15%\" }\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIDIxZaJTcK2",
        "cellView": "form"
      },
      "source": [
        "#@title Module Imports HEADER { form-width: \"15%\" }\n",
        "from openbiolink.obl2021 import OBL2021Dataset\n",
        "import torch\n",
        "from torch.nn import Module,\\\n",
        "                     ModuleList,\\\n",
        "                     Embedding,\\\n",
        "                     BatchNorm1d,\\\n",
        "                     LogSoftmax,\\\n",
        "                     Softmax,\\\n",
        "                     Linear,\\\n",
        "                     NLLLoss,\\\n",
        "                     CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric as PyG\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn.conv import RGCNConv\n",
        "from torch_geometric.utils import to_networkx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from typing import NoReturn\n",
        "from enum import Enum\n",
        "from collections import defaultdict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-0w2buqhHoS",
        "cellView": "form"
      },
      "source": [
        "#@title Global Variables CLASS { form-width: \"15%\" }\n",
        "class Global(Enum):\n",
        "  HEAD_INDEX = 0\n",
        "  RELATION_INDEX = 1\n",
        "  TAIL_INDEX = 2\n",
        "  FEATURE_ENG = 'one-hot'\n",
        "  NUM_RELATIONS = 28\n",
        "  DEVICE = 'cpu'\n",
        "  MINI_BATCH_SIZE = 32"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IqWPI4Bh_Q1",
        "cellView": "form"
      },
      "source": [
        "#@title add_tail_to_head(data_split) FUNCTION { form-width: \"15%\" }\n",
        "def add_tail_to_head(data_split: torch.Tensor, plus: int=28) -> torch.Tensor:\n",
        "  heads = data_split[:, (0)]\n",
        "  tails = data_split[:, (-1)]\n",
        "  relations = data_split[:, (1)]\n",
        "  \n",
        "  tail_to_head = torch.vstack(\n",
        "      (tails, relations + plus, heads)\n",
        "  ).t()\n",
        "\n",
        "  return torch.cat(\n",
        "      (data_split, tail_to_head),\n",
        "      dim=0\n",
        "  )\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV0mkcK1rMhq",
        "cellView": "form"
      },
      "source": [
        "#@title checksum(data_subset, graph_data) FUNCTION { form-width: \"15%\" }\n",
        "def checksum(data_subset: torch.Tensor, graph_data: Data, step: int=500) -> NoReturn:\n",
        "  for i in range(step, data_subset.shape[0], step):\n",
        "    graph_head_indcs = graph_data.edge_index[0, i-step:i]\n",
        "    data_head_entities = data_subset[i-step:i, 0]\n",
        "    graph_head_entities = graph_data.x[graph_head_indcs].reshape(-1)\n",
        "\n",
        "    checksum_head = (graph_head_entities == data_head_entities).sum().item()\n",
        "    if not checksum_head == step:\n",
        "      print('head')\n",
        "      print(i)\n",
        "      break\n",
        "\n",
        "    graph_relation_indcs = graph_data.edge_type[i-step:i]\n",
        "    data_relation_types = data_subset[i-step:i, 1]\n",
        "\n",
        "    checksum_relation = (graph_relation_indcs == data_relation_types).sum().item()\n",
        "    if not checksum_relation == step:\n",
        "      print('relation')\n",
        "      print(i)\n",
        "      break\n",
        "\n",
        "    graph_tail_indcs = graph_data.edge_index[1, i-step:i]\n",
        "    data_tail_entities = data_subset[i-step:i, 2]\n",
        "    graph_tail_entities = graph_data.x[graph_tail_indcs].reshape(-1)\n",
        "\n",
        "    checksum_tail = (graph_tail_entities == data_tail_entities).sum().item()\n",
        "    if not checksum_head == step:\n",
        "      print('tail')\n",
        "      print(i)\n",
        "      break\n",
        "\n",
        "  else:\n",
        "    print('All clear :)')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmd5ucYzDcqN",
        "cellView": "form"
      },
      "source": [
        "#@title graph_data_maker(dataset, x_feature) FUNCTION{ form-width: \"15%\" }\n",
        "def graph_data_maker(messaging: torch.Tensor, supervision: torch.Tensor, negative_samples: torch.Tensor, x_feature: str=Global.FEATURE_ENG.value, check_for_correctness: bool=False) -> Data:\n",
        "  relation_idx = Global.RELATION_INDEX.value\n",
        "  head_idx = Global.HEAD_INDEX.value\n",
        "  tail_idx = Global.TAIL_INDEX.value\n",
        "\n",
        "  if x_feature == 'one-hot':\n",
        "    one_hot_index = 0\n",
        "    edge_index_list_flat = []\n",
        "    seen_dict = defaultdict(lambda: -1)\n",
        "    edge_index_flat = messaging[:, (head_idx, tail_idx)].reshape(-1)\n",
        "\n",
        "    for i in range(edge_index_flat.shape[0]):\n",
        "      entity = edge_index_flat[i].item()\n",
        "      if seen_dict[entity] == -1:\n",
        "        edge_index_list_flat.append(one_hot_index)\n",
        "        seen_dict[entity] = one_hot_index\n",
        "        one_hot_index += 1\n",
        "      else:\n",
        "        edge_index_list_flat.append(seen_dict[entity])\n",
        "      if i + 1 % 50000 == 0:\n",
        "        print(f'Entity {i} encoded. {i / edge_index_flat.shape[0] * 100:.2f} %')\n",
        "    edge_index_messaging = torch.tensor(edge_index_list_flat).reshape(-1, 2)\n",
        "    ##############################################################\n",
        "    edge_index_flat = supervision[:, (head_idx, tail_idx)].reshape(-1)\n",
        "    edge_index_list_flat = []\n",
        "\n",
        "    for i in range(edge_index_flat.shape[0]):\n",
        "      entity = edge_index_flat[i].item()\n",
        "      if seen_dict[entity] == -1:\n",
        "        edge_index_list_flat.append(one_hot_index)\n",
        "        seen_dict[entity] = one_hot_index\n",
        "        one_hot_index += 1\n",
        "      else:\n",
        "        edge_index_list_flat.append(seen_dict[entity])\n",
        "      if i + 1 % 50000 == 0:\n",
        "        print(f'Entity {i} encoded. {i / edge_index_flat.shape[0] * 100:.2f} %')\n",
        "    edge_index_supervision = torch.tensor(edge_index_list_flat).reshape(-1, 2)\n",
        "    ##############################################################\n",
        "    edge_index_flat = negative_samples[:, (head_idx, tail_idx)].reshape(-1)\n",
        "    edge_index_list_flat = []\n",
        "\n",
        "    for i in range(edge_index_flat.shape[0]):\n",
        "      entity = edge_index_flat[i].item()\n",
        "      if seen_dict[entity] == -1:\n",
        "        edge_index_list_flat.append(one_hot_index)\n",
        "        seen_dict[entity] = one_hot_index\n",
        "        one_hot_index += 1\n",
        "      else:\n",
        "        edge_index_list_flat.append(seen_dict[entity])\n",
        "      if i + 1 % 50000 == 0:\n",
        "        print(f'Entity {i} encoded. {i / edge_index_flat.shape[0] * 100:.2f} %')\n",
        "    edge_index_negative = torch.tensor(edge_index_list_flat).reshape(-1, 2)\n",
        "    ##############################################################\n",
        "    x = torch.tensor(list(seen_dict.keys())).reshape(-1, 1)\n",
        "\n",
        "    graph_data = Data(\n",
        "        x=x,\n",
        "        edge_index_messaging=edge_index_messaging.t().contiguous(),\n",
        "        edge_type_messaging=messaging[:, relation_idx],\n",
        "        edge_index_supervision=edge_index_supervision.t().contiguous(),\n",
        "        edge_type_supervision=supervision[:, relation_idx],\n",
        "        edge_index_negative=edge_index_negative.t().contiguous(),\n",
        "        edge_type_negative=negative_samples[:, (relation_idx)]\n",
        "    )\n",
        "  else:\n",
        "    raise NotImplementedError('This functionality has not been implemented yet.')\n",
        "\n",
        "  if check_for_correctness:\n",
        "    checksum(dataset, graph_data)\n",
        "  return graph_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8jt1Q1RoExW",
        "cellView": "form"
      },
      "source": [
        "#@title visualize_graph(graph_data, height, width) FUNCTION{ form-width: \"15%\" }\n",
        "def visualize_graph(graph_data: Data, height: int=10, width:int=10) -> NoReturn:\n",
        "  nx_graph = to_networkx(graph_data)\n",
        "\n",
        "  pos = nx.spring_layout(nx_graph)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(width, height)\n",
        "\n",
        "  edge_labels = dict()\n",
        "  ei_np = graph_data.edge_index.t().numpy()\n",
        "  for edge in nx_graph.edges():\n",
        "    e = np.array(edge)\n",
        "    idx = np.where(ei_np == e)[0][0]\n",
        "    label = graph_data.edge_type[idx].item()\n",
        "    edge_labels.update({edge: label})\n",
        "    \n",
        "  nx.draw_networkx_nodes(nx_graph, pos)\n",
        "  nx.draw_networkx_edges(nx_graph, pos, connectionstyle='arc3,rad=0.2')\n",
        "  nx.draw_networkx_labels(nx_graph, pos, labels={n:graph_data.x[n].item() for n in nx_graph})\n",
        "  nx.draw_networkx_edge_labels(nx_graph, pos, edge_labels=edge_labels)\n",
        "\n",
        "  fig.show()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EDUweUw5uvi"
      },
      "source": [
        "#@title GNN Model CLASS{ form-width: \"10%\" }\n",
        "class GNN(Module):\n",
        "  def __init__(self, conv_dims: list, fully_connected_dims: list, x_feature:str, dropout: dict, embedding_dims: tuple=None)-> NoReturn:\n",
        "    super(GNN, self).__init__()\n",
        "    self.mode = None # 'train' or 'test' or 'dev' later \n",
        "    self.num_relations = Global.NUM_RELATIONS.value\n",
        "    self.dropout = dropout\n",
        "    self.x_feature = x_feature\n",
        "    relation_weights_list = [Linear(16, 16, bias=False) for _ in range(28)]\n",
        "    self.relation_weights = ModuleList(relation_weights_list)\n",
        "    if x_feature == 'one-hot':\n",
        "      #one-hot to latent\n",
        "      self.embed = Embedding(embedding_dims[0], embedding_dims[1])\n",
        "      first_conv_layer = [RGCNConv(embedding_dims[1], conv_dims[0], self.num_relations)]\n",
        "    elif x_feature == 'identity':\n",
        "      first_conv_layer = [RGCNConv(1, conv_dims[0], self.num_relations)]\n",
        "    conv_list = first_conv_layer + \\\n",
        "                                [\n",
        "                                  RGCNConv(conv_dims[i], conv_dims[i+1], self.num_relations)\n",
        "                                  for i in range(len(conv_dims[:-1]))\n",
        "                                ]\n",
        "  \n",
        "\n",
        "    # fully_connected_list =   [\n",
        "    #                             Linear(2*conv_dims[-1], fully_connected_dims[0])\n",
        "    #                          ] + \\\n",
        "    #                          [\n",
        "    #                             Linear(fully_connected_dims[i], fully_connected_dims[i+1])\n",
        "    #                             for i in range(len(fully_connected_dims[:-1]))\n",
        "    #                          ] + \\\n",
        "    #                          [\n",
        "    #                             Linear(fully_connected_dims[-1], self.output_dim)\n",
        "    #                          ]\n",
        "\n",
        "    #graph conv layers\n",
        "    self.conv_layers = ModuleList(conv_list)\n",
        "\n",
        "    #fully connected dense layers\n",
        "    # self.fully_connected_layers = ModuleList(fully_connected_list)\n",
        "\n",
        "    self.classifier = LogSoftmax(dim=1)\n",
        "\n",
        "    \n",
        "  def reset_parameters(self):\n",
        "    self.embed.reset_parameters\n",
        "    for conv in self.conv_layers:\n",
        "        conv.reset_parameters()\n",
        "    # for fc in self.fully_connected_layers:\n",
        "    #     fc.reset_parameters()\n",
        "      \n",
        "\n",
        "  def forward(self, data: Data) -> torch.Tensor:\n",
        "    edge_index = data.edge_index_messaging\n",
        "    x = data.x\n",
        "    edge_type = data.edge_type_messaging\n",
        "\n",
        "    # print(x.shape)\n",
        "    # return\n",
        "    ####################################### ONE - HOT #######################################\n",
        "    if self.x_feature == 'one-hot':\n",
        "      latent = list()\n",
        "      last_index = 0\n",
        "      for i in range(0, x.shape[0] - 1024, 1024):\n",
        "        latent.append(self.embed(x[i: i+1024, :]))\n",
        "        last_index = i\n",
        "      last_latent = self.embed(x[last_index:, : ]).reshape(-1, self.embed.weight.shape[1])\n",
        "      partial_latent_space = torch.stack(latent).reshape(-1, self.embed.weight.shape[1])\n",
        "      x = torch.cat(\n",
        "          (partial_latent_space, last_latent),\n",
        "          dim=0 \n",
        "      )\n",
        "      \n",
        "    ####################################### Encoder: RGCN #######################################\n",
        "      \n",
        "    ############################################## IDENTITY ################################################\n",
        "    elif self.x_feature == 'identity':\n",
        "      x = torch.ones(x.shape[0], 1) ############KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKk\n",
        "      if self.training:\n",
        "        x = F.dropout(x, p=self.dropout[\"emb\"])\n",
        "      print(f'Embedding {x.shape}')\n",
        "    ####################################### Encoder: RGCN #######################################\n",
        "    for conv in self.conv_layers[:-1]:\n",
        "      x = conv(x, edge_index=edge_index, edge_type=edge_type)\n",
        "      x = F.relu(x)\n",
        "      if self.training:\n",
        "        x = F.dropout(x, p=self.dropout[\"conv\"])\n",
        "    x = self.conv_layers[-1](x, edge_index, edge_type)\n",
        "    if self.training:\n",
        "      x = F.dropout(x, p=self.dropout[\"conv\"])\n",
        "\n",
        "    ####################################### Decoder #######################################\n",
        "    n_scores = list()\n",
        "    for index, n_edge_relation in enumerate(data.edge_type_negative):\n",
        "      weights = self.relation_weights[n_edge_relation]\n",
        "      head = x[data.edge_index_negative[0, index]]\n",
        "      tail = x[data.edge_index_negative[1, index]]\n",
        "      score = weights(head) @ tail \n",
        "      n_scores.append(score)\n",
        "    p_scores = list()\n",
        "    for index, p_edge_relation in enumerate(data.edge_type_supervision):\n",
        "      weights = self.relation_weights[p_edge_relation]\n",
        "      head = x[data.edge_index_supervision[0, index]]\n",
        "      tail = x[data.edge_index_supervision[1, index]]\n",
        "      score = weights(head) @ tail \n",
        "      p_scores.append(score)\n",
        "    return torch.stack(n_scores), torch.stack(p_scores)\n",
        "    \n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5SkTuG_8R1v",
        "cellView": "form"
      },
      "source": [
        "#@title Dataset Load and Train/Val/Test Split MAIN 1{ form-width: \"15%\" }\n",
        "dataset = OBL2021Dataset()\n",
        "train_set = dataset.training # torch.tensor of shape(num_train,3)\n",
        "val_set = dataset.validation # torch.tensor of shape(num_val,3)\n",
        "test_set = dataset.testing   # torch.tensor of shape(num_train,3)\n",
        "knowledge_graph = torch.cat(\n",
        "    (dataset.training, dataset.validation, dataset.testing),\n",
        "    dim=0\n",
        ")\n",
        "\n",
        "# train_list = list()\n",
        "# gg = list()\n",
        "for i in tqdm(range(0, train_set.shape[0], Global.MINI_BATCH_SIZE.value)):\n",
        "  train_supervision = train_set[i: i + Global.MINI_BATCH_SIZE.value, :]\n",
        "\n",
        "  heads = train_supervision[:, 0]\n",
        "  relations = train_supervision[:, 1]\n",
        "  tails = train_supervision[:, -1]\n",
        "\n",
        "  negative_samples = torch.vstack(\n",
        "      (heads, relations, torch.multinomial(dataset.candidates.type(torch.float), Global.MINI_BATCH_SIZE.value))\n",
        "  ).t().contiguous()\n",
        "\n",
        "  train_messaging = torch.cat(\n",
        "      (train_set[: i, :], train_set[i + Global.MINI_BATCH_SIZE.value: , :]),\n",
        "      dim=0\n",
        "  )\n",
        "\n",
        "  for __index, candidate in enumerate(negative_samples):\n",
        "    is_corrupt = not any(np.equal(knowledge_graph.numpy(), candidate.numpy().tolist()).all(1))\n",
        "    if not is_corrupt:\n",
        "      print(f'{candidate} at [{_index}][{__index}] is not a true corrupted edge')\n",
        "\n",
        "  g = graph_data_maker(train_messaging, train_supervision, negative_samples, 'one-hot', False)\n",
        "  # gg.append(g)\n",
        "\n",
        "  # you can run model(g) on it\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq9CoeHZ7SHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "f6ec58fb-b182-4623-fb19-a35aede07795"
      },
      "source": [
        "#@title Model and Hyperparameters MAIN { form-width: \"15%\" }\n",
        "model = GNN(\n",
        "    x_feature='one-hot',\n",
        "    conv_dims=[16, 16, 16],\n",
        "    embedding_dims=(dataset.candidates.max() + 1, 32),\n",
        "    fully_connected_dims=[1], \n",
        "    dropout={\n",
        "        \"emb\": 0.01,\n",
        "        \"conv\": 0.01,\n",
        "        \"fc\": 0.01\n",
        "    }\n",
        ").to(Global.DEVICE.value)\n",
        "print(model)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN(\n",
            "  (relation_weights): ModuleList(\n",
            "    (0): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (1): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (2): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (3): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (4): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (5): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (6): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (7): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (8): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (9): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (10): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (11): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (12): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (13): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (14): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (15): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (16): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (17): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (18): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (19): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (20): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (21): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (22): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (23): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (24): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (25): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (26): Linear(in_features=16, out_features=16, bias=False)\n",
            "    (27): Linear(in_features=16, out_features=16, bias=False)\n",
            "  )\n",
            "  (embed): Embedding(180992, 32)\n",
            "  (conv_layers): ModuleList(\n",
            "    (0): RGCNConv(32, 16, num_relations=28)\n",
            "    (1): RGCNConv(16, 16, num_relations=28)\n",
            "    (2): RGCNConv(16, 16, num_relations=28)\n",
            "  )\n",
            "  (classifier): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzR8BWA0N628"
      },
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "opt = Adam(model.parameters())\n",
        "\n",
        "\n",
        "def train(model, graph, optimizer, loss_fn):\n",
        "  optimizer.zero_grad()\n",
        "  negative, positive = model(graph)\n",
        "  loss = loss_fn(negative, torch.zeros(32)) + loss_fn(positive, torch.ones(32))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item(), torch.sigmoid(positive), torch.sigmoid(negative)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, graph):\n",
        "  negative, positive = model(graph)\n",
        "  return positive, negative\n",
        "\n",
        "\n",
        "for i in range(320):\n",
        "  l, p, n = train(model, g, opt, loss_fn)\n",
        "  # pp, nn = evaluate(model, gg[1])\n",
        "  print(f'Iteration {i+1}, Loss: {l: .4f}, P-Score: {p.sum().item(): .4f}, N-Score: {n.sum().item(): .4f}')\n",
        "  # print(f'Dev: {pp.sum().item()}, {nn.sum().item()}')\n",
        "  print('================================================================================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaarJu2fzJ68",
        "cellView": "form"
      },
      "source": [
        "#@title Visualization OPTIONAL-MAIN { form-width: \"15%\" }\n",
        "data_subset = train_set[:2500, :]\n",
        "graph_data = graph_data_maker(data_subset, 'one-hot')\n",
        "visualize_graph(graph_data, 100, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ciX_cKCvMHY",
        "cellView": "form"
      },
      "source": [
        "#@title Mostly Trash { form-width: \"15%\" }\n",
        "# ! pip install deepsnap\n",
        "# import deepsnap\n",
        "\n",
        "\n",
        "# NX_graph = PyG.utils.to_networkx(train_graph)\n",
        "# SX_graph = deepsnap.graph.Graph(NX_graph)\n",
        "\n",
        "# SX_graph\n",
        "# SX_graph.negative_sampling(SX_graph.edge_index, SX_graph.num_nodes, 100)\n",
        "# #@title\n",
        "# print(min([i[1].shape[0] for i in train_list]))\n",
        "# #@title\n",
        "# d = defaultdict(lambda: 0)\n",
        "# for i in dataset.training:\n",
        "#   h = i[0]\n",
        "#   t = i[-1]\n",
        "#   d[h.item()] += 1\n",
        "#   d[t.item()] += 1\n",
        "# new_list = list()\n",
        "# other_list = list()\n",
        "# ################################################################################################################\n",
        "# new_candidates = torch.tensor(list(filter(lambda z: z[1] > 1000, sorted(d.items(), key= lambda z: z[1]))))[:, 0]\n",
        "# ################################################################################################################\n",
        "# for i in tqdm(dataset.training):\n",
        "#   h = i[0]\n",
        "#   t = i[-1]\n",
        "#   if h in new_candidates or t in new_candidates:\n",
        "#     new_list.append(i)\n",
        "#   else:\n",
        "#     other_list.append(i)\n",
        "# #@title\n",
        "# for i in train_list:\n",
        "#   print(torch.unique(i[1]).shape)\n",
        "# #@title\n",
        "\n",
        "# # #@title Dataset Load and Train/Val/Test Split MAIN 2{ form-width: \"15%\" }\n",
        "# # dataset = OBL2021Dataset()\n",
        "# # train_set = dataset.training # torch.tensor of shape(num_train,3)\n",
        "# # val_set = dataset.validation # torch.tensor of shape(num_val,3)\n",
        "# # test_set = dataset.testing   # torch.tensor of shape(num_train,3)\n",
        "\n",
        "# # train_supervision, train_messaging = torch.split(\n",
        "# #     torch.stack(new_list)[torch.randperm(torch.stack(new_list).shape[0])],\n",
        "# #     split_size_or_sections=(\n",
        "# #         Global.TRAIN_SUPERVISION_SIZE.value,\n",
        "# #         torch.stack(new_list).shape[0] - Global.TRAIN_SUPERVISION_SIZE.value\n",
        "# #     )\n",
        "# # )\n",
        "# # train_supervision_data_loader = torch.split(train_supervision, split_size_or_sections=32)\n",
        "# # train_supervision_negative_samples = [None for _ in range(Global.TRAIN_SUPERVISION_SIZE.value // 32)]\n",
        "# # for i in range(Global.TRAIN_SUPERVISION_SIZE.value // 32):\n",
        "# #   heads = train_supervision_data_loader[i][:, 0]\n",
        "# #   relations = train_supervision_data_loader[i][:, 1]\n",
        "# #   tails = train_supervision_data_loader[i][:, -1]\n",
        "# #   negative_samples = torch.vstack(\n",
        "# #       (heads, relations, torch.multinomial(dataset.candidates.type(torch.float), 32))\n",
        "# #   ).t().contiguous()\n",
        "# #   train_supervision_negative_samples[i] = negative_samples\n",
        "# # knowledge_graph = torch.cat(\n",
        "# #     (dataset.training, dataset.validation, dataset.testing),\n",
        "# #     dim=0\n",
        "# # )\n",
        "\n",
        "# # # for _index, mini_batch in enumerate(tqdm(train_supervision_negative_samples)):\n",
        "# # #   for __index, candidate in enumerate(mini_batch):\n",
        "# # #     is_corrupt = not any(np.equal(knowledge_graph.numpy(), candidate.numpy().tolist()).all(1))\n",
        "# # #     if not is_corrupt:\n",
        "# # #       print(f'{candidate} at [{_index}][{__index}] is not a true corrupted edge')\n",
        "\n",
        "# #@title\n",
        "\n",
        "# torch.unique(torch.cat(\n",
        "#     (train_messaging, torch.stack(other_list)),\n",
        "#     dim=0\n",
        "# )).shape\n",
        "# #@title\n",
        "# torch.split(\n",
        "#     torch.tensor([_ for _ in range(1, 15)])[torch.randperm(14)],\n",
        "#     split_size_or_sections = (7, 7)\n",
        "# )\n",
        "# #@title\n",
        "# train_supervision, train_messaging = torch.split(\n",
        "#     torch.stack(new_list),\n",
        "#     split_size_or_sections=(\n",
        "#         3,\n",
        "#         torch.stack(new_list).shape[0] - 3\n",
        "#     )\n",
        "# )\n",
        "# #@title\n",
        "# torch.unique(train_messaging).shape\n",
        "# #@title\n",
        "# torch.unique(torch.stack(other_list + new_list)).shape\n",
        "# # torch.cat(\n",
        "# #     (train_messaging, torch.stack(other_list)),\n",
        "# #     dim=0\n",
        "# # ).shape\n",
        "# # train_supervision.shape\n",
        "# #@title\n",
        "# # d = defaultdict(lambda: 0)\n",
        "# # for i in dataset.training:\n",
        "# #   h = i[0]\n",
        "# #   t = i[-1]\n",
        "# #   d[h.item()] += 1\n",
        "# #   d[t.item()] += 1\n",
        "# new_list = list()\n",
        "# other_list = list()\n",
        "# ################################################################################################################\n",
        "# new_candidates = torch.tensor(list(filter(lambda z: z[1] > 1000, sorted(d.items(), key= lambda z: z[1]))))[:, 0]\n",
        "# ################################################################################################################\n",
        "# for i in tqdm(dataset.training):\n",
        "#   h = i[0]\n",
        "#   t = i[-1]\n",
        "#   if h in new_candidates or t in new_candidates:\n",
        "#     new_list.append(i)\n",
        "#   else:\n",
        "#     other_list.append(i)\n",
        "\n",
        "# #@title\n",
        "# torch.stack(new_list).shape\n",
        "# dataset.training.shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}